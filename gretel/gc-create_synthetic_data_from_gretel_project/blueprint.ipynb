{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "blueprint.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51-WSOJ5HEWe"
      },
      "source": [
        "# Create synthetic data from a Gretel Cloud Project\n",
        "\n",
        "This Blueprint will walk you through consuming records from a Gretel Cloud Project and creating synthetic data from it. This blueprint assumes you already have a Gretel Cloud Projeect created with records uploaded. If you do not, feel free to create a new project from our console (https://console.gretel.cloud) and select this blueprint. Sample data will automatically be uploaded for you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhmOfAQmHEWk"
      },
      "source": [
        "%%capture\n",
        "\n",
        "!pip install -U gretel-client gretel-synthetics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWchMCrVHEWl"
      },
      "source": [
        "# Be sure to use your Gretel URI here, which is available from the Integration menu in the Console\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "gretel_uri = os.getenv(\"GRETEL_URI\") or getpass.getpass(\"Your Gretel URI\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9j8wqGpOHEWl"
      },
      "source": [
        "# Install Gretel SDKs\n",
        "\n",
        "from gretel_client import project_from_uri\n",
        "\n",
        "project = project_from_uri(gretel_uri)\n",
        "project.client.install_packages()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaZkANRmxXOg"
      },
      "source": [
        "# Capture transient import errors in Google Colab\n",
        "\n",
        "try:\n",
        "    from gretel_helpers.synthetics import SyntheticDataBundle\n",
        "except FileNotFoundError:\n",
        "    from gretel_helpers.synthetics import SyntheticDataBundle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8N5uBzsHEWm"
      },
      "source": [
        "# Download records from Gretel Cloud and create a training DataFrame\n",
        "\n",
        "from gretel_helpers.synthetics import create_df, SyntheticDataBundle\n",
        "\n",
        "training_df = create_df(\n",
        "    gretel_uri,\n",
        "    num_rows=15000  # set to ``None`` to include all records\n",
        ")\n",
        "\n",
        "# Preview the data that will be synthesized\n",
        "training_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjRTEGKhHEWm"
      },
      "source": [
        "# Create synthetic training configuration\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "checkpoint_dir = str(Path.cwd() / \"checkpoints\")\n",
        "\n",
        "# All params: https://gretel-synthetics.readthedocs.io/en/stable/api/config.html\n",
        "config_template = {\n",
        "    \"checkpoint_dir\": checkpoint_dir,\n",
        "    \"vocab_size\": 20000\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9paRNJuHEWn"
      },
      "source": [
        "# Create a model object, which provides high level API interfaces for building / saving / generating synthetic data\n",
        "\n",
        "model = SyntheticDataBundle(\n",
        "    training_df=training_df,\n",
        "    delimiter=None, # if ``None``, it will try and automatically be detected, otherwise you can set it\n",
        "    auto_validate=True, # build record validators that learn per-column, these are used to ensure generated records have the same composition as the original\n",
        "    synthetic_config=config_template, # the config for Synthetics\n",
        "    synthetic_batch_size=30, # cluster up to this many fields per individual model\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbX8PPfsHEWn"
      },
      "source": [
        "# Create model metadata\n",
        "\n",
        "model.build()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35G_L5mwHEWn"
      },
      "source": [
        "# Train the model\n",
        "\n",
        "model.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDKs-udkHEWn"
      },
      "source": [
        "# Generate some data\n",
        "\n",
        "model.generate(num_lines=5000, max_invalid=5000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgGaqHxxHEWo"
      },
      "source": [
        "# Re-assemble synthetic data back into a DataFrame\n",
        "\n",
        "model.get_synthetic_df()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h95hAA3ZHEWo"
      },
      "source": [
        "# Save your model, you can load this back into a Bundle later on\n",
        "\n",
        "model.save(\"my_model.tar.gz\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYDqkp91HEWo"
      },
      "source": [
        "# Generate a report that shows how the new synthetic data compares to the original training data\n",
        "import IPython\n",
        "\n",
        "report_path = './report.html'\n",
        "model.generate_report(report_path=report_path)\n",
        "IPython.display.HTML(filename=report_path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
