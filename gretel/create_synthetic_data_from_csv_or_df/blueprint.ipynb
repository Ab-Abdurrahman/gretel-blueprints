{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "blueprint.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTRxpSlaczHY"
      },
      "source": [
        "# Create a synthetic version of your own CSV or DataFrame\n",
        "\n",
        "This blueprint utilizes Gretel's premium SDKs to create a synthetic version of your own data. Our SDKs create automatic data validators to help ensure the data generated has the same semantics as the source data. Additionally, the SDKs do autmoatic header clustering to help maintain statistical relations between columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEM6kjRsczHd"
      },
      "source": [
        "%%capture\n",
        "\n",
        "!pip install -U gretel-client gretel-synthetics pandas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQ-TmAdwczHd"
      },
      "source": [
        "# Load your Gretel API key. You can acquire this from the Gretel Console \n",
        "# @ https://console.gretel.cloud\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "from gretel_client import project_from_uri\n",
        "\n",
        "gretel_uri = os.getenv(\"GRETEL_URI\") or getpass.getpass(\"Your Gretel URI\")\n",
        "\n",
        "project = project_from_uri(gretel_uri)\n",
        "project.client.install_packages()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMg9nX6SczHe"
      },
      "source": [
        "# Load and preview dataset\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "dataset_path = 'https://gretel-public-website.s3-us-west-2.amazonaws.com/datasets/healthcare-analytics-vidhya/train_data.csv'\n",
        "nrows = 10000  # We will use this later when generating data\n",
        "training_df = pd.read_csv(dataset_path, nrows=nrows)\n",
        "training_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4-E_F0qczHe"
      },
      "source": [
        "# Create the Gretel Synthtetics Training / Model Configuration\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "checkpoint_dir = str(Path.cwd() / \"checkpoints\")\n",
        "\n",
        "config_template = {\n",
        "    \"checkpoint_dir\": checkpoint_dir,\n",
        "    \"vocab_size\": 20000,\n",
        "    \"overwrite\": True\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCW-JaiNczHf"
      },
      "source": [
        "# Create a Gretel Synthetic Data Bundle\n",
        "\n",
        "from gretel_helpers.synthetics import create_df, SyntheticDataBundle\n",
        "\n",
        "model = SyntheticDataBundle(\n",
        "    training_df=training_df,\n",
        "    delimiter=None, # if ``None``, it will try and automatically be detected, otherwise you can set it\n",
        "    auto_validate=True, # build record validators that learn per-column, these are used to ensure generated records have the same composition as the original\n",
        "    synthetic_config=config_template, # the config for Synthetics\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NshnGoobczHf"
      },
      "source": [
        "model.build()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocX625j-czHf"
      },
      "source": [
        "model.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPM-gaU6czHf"
      },
      "source": [
        "# num_lines: how many rows to generate\n",
        "# max_invalid: the number of rows that do not pass semantic validation, if this number is exceeded, training will\n",
        "# stop\n",
        "model.generate(num_lines=nrows, max_invalid=nrows)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbB7vnisczHg"
      },
      "source": [
        "model.get_synthetic_df().head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX8qsizqczHg"
      },
      "source": [
        "# Generate report that shows the statistical performance between the training and synthetic data\n",
        "import IPython\n",
        "\n",
        "report_path = './report.html'\n",
        "model.generate_report(report_path=report_path)\n",
        "IPython.display.HTML(filename=report_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWXis_7TczHg"
      },
      "source": [
        "# Optionally save your model\n",
        "\n",
        "model.save(\"my_model.tar.gz\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srW1HBA-d3Mp"
      },
      "source": [
        "# Save synthetic dataframe locally and to a private Gretel project \n",
        "\n",
        "import time\n",
        "\n",
        "def publish(project, model, clear=False):\n",
        "    \"\"\" Save synthetic and test data to the project stream \"\"\"\n",
        "\n",
        "    if clear:\n",
        "        project.flush()\n",
        "        time.sleep(2)\n",
        "    elif project.record_count > 0:\n",
        "        print(\"ERROR: Publishing to non-empty data project, aborting.\")\n",
        "        print(\"To overwrite existing project records, use clear=True\")\n",
        "        return\n",
        "\n",
        "    project.send_dataframe(df, detection_mode='fast')  \n",
        "    print(f\"\\nSuccessfully published to private dataset\")\n",
        "    print(f\"Access your project at {project.get_console_url()}\")  \n",
        "\n",
        "\n",
        "df = model.get_synthetic_df()\n",
        "df.to_csv('synthetic-data.csv', index=False)\n",
        "\n",
        "# Publish newly created synthetic data to a new private Gretel project \n",
        "publish(project, df, clear=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}